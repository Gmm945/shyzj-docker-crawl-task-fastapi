FROM python:3.9-slim

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    libxml2-dev \
    libxslt1-dev \
    zlib1g-dev \
    && rm -rf /var/lib/apt/lists/*

# 设置工作目录
WORKDIR /app

# 复制Python依赖文件
COPY requirements.crawler.txt /app/requirements.txt

# 安装Python依赖
RUN pip install --no-cache-dir -r requirements.txt

# 复制爬虫服务代码
COPY src/worker/crawler_service.py /app/

# 创建配置和输出目录
RUN mkdir -p /app/config /app/output

# 设置环境变量
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV API_BASE_URL=http://data-platform-api:8000

# 创建非root用户
RUN useradd -m -u 1000 crawler && \
    chown -R crawler:crawler /app
USER crawler

# 运行爬虫服务
CMD ["python", "crawler_service.py"]
