# 任务配置文件示例

## 概述

本文档展示了如何使用新的配置文件部署机制来执行Docker任务。配置文件会被上传到远程执行机器，并通过Docker卷挂载的方式提供给容器内的服务。

## 配置文件结构

### 爬虫任务配置示例

```json
{
  "task_name": "电商网站爬虫",
  "task_type": "crawler",
  "base_url": "https://example-ecommerce.com",
  "docker_image": "data-collection-crawler:latest",
  "crawler_config": {
    "target_urls": [
      "https://example-ecommerce.com/products",
      "https://example-ecommerce.com/categories"
    ],
    "max_pages": 100,
    "delay": 2,
    "user_agent": "Mozilla/5.0 (compatible; DataCollector/1.0)",
    "output_format": "json",
    "data_fields": [
      "product_name",
      "price",
      "description",
      "category",
      "availability"
    ]
  },
  "storage_config": {
    "output_path": "/app/output",
    "filename_prefix": "ecommerce_products"
  }
}
```

### API任务配置示例

```json
{
  "task_name": "第三方API数据采集",
  "task_type": "api",
  "base_url": "https://api.external-service.com",
  "docker_image": "data-collection-api:latest",
  "api_config": {
    "endpoints": [
      "/v1/users",
      "/v1/orders",
      "/v1/products"
    ],
    "auth_type": "bearer_token",
    "api_key": "your-api-key-here",
    "rate_limit": {
      "requests_per_minute": 60,
      "burst_limit": 10
    },
    "retry_config": {
      "max_retries": 3,
      "backoff_factor": 2
    }
  },
  "output_config": {
    "format": "json",
    "compression": "gzip"
  }
}
```

### 数据库任务配置示例

```json
{
  "task_name": "数据库数据同步",
  "task_type": "database",
  "docker_image": "data-collection-database:latest",
  "database_config": {
    "source_db": {
      "type": "mysql",
      "host": "source-db.example.com",
      "port": 3306,
      "database": "source_db",
      "username": "sync_user",
      "password": "secure_password"
    },
    "target_db": {
      "type": "postgresql",
      "host": "target-db.example.com",
      "port": 5432,
      "database": "target_db",
      "username": "sync_user",
      "password": "secure_password"
    },
    "sync_config": {
      "tables": [
        {
          "source_table": "users",
          "target_table": "users_sync",
          "batch_size": 1000
        },
        {
          "source_table": "orders",
          "target_table": "orders_sync",
          "batch_size": 500
        }
      ],
      "incremental_sync": true,
      "last_sync_field": "updated_at"
    }
  },
  "backup_config": {
    "enable_backup": true,
    "backup_path": "/app/backups"
  }
}
```

## 工作流程

### 1. 配置文件处理流程

1. **本地处理**: 配置文件首先在本地保存到 `/tmp/task_configs/{execution_id}/config.json`
2. **远程上传**: 通过SCP将配置文件上传到远程执行机器的 `/tmp/task_configs/{execution_id}/config.json`
3. **Docker挂载**: 启动Docker容器时，将配置文件挂载到容器的 `/app/config/config.json`

### 2. Docker容器启动

```bash
docker run -d \
  --name task-{execution_id} \
  --rm \
  -v /tmp/task_configs/{execution_id}/config.json:/app/config/config.json:ro \
  -v /tmp/task_outputs:/app/output \
  -e TASK_EXECUTION_ID={execution_id} \
  -e CONFIG_PATH=/app/config/config.json \
  {docker_image}
```

### 3. 容器内服务读取配置

容器内的服务可以通过以下方式读取配置：

```python
import json
import os

# 从环境变量获取配置文件路径
config_path = os.getenv('CONFIG_PATH', '/app/config/config.json')

# 读取配置文件
with open(config_path, 'r', encoding='utf-8') as f:
    config = json.load(f)

# 使用配置
print(f"任务名称: {config['task_name']}")
print(f"任务类型: {config['task_type']}")
```

### 4. 任务执行监控

- 容器启动后，系统会定期检查容器日志
- 通过日志中的关键字判断任务状态：
  - `TASK_COMPLETED` - 任务完成
  - `TASK_FAILED` - 任务失败
  - `API_TASK_COMPLETED` - API任务完成
  - `DB_TASK_COMPLETED` - 数据库任务完成

### 5. 清理机制

任务完成后会自动清理：
- 停止并删除Docker容器
- 删除远程配置文件
- 清理本地临时文件

## 环境变量

容器启动时会自动设置以下环境变量：

- `TASK_EXECUTION_ID`: 任务执行ID
- `CONFIG_PATH`: 配置文件在容器内的路径

## 注意事项

1. **安全性**: 配置文件包含敏感信息时，确保远程机器和网络连接的安全性
2. **权限**: 确保SSH用户有足够的权限在远程机器上创建目录和文件
3. **网络**: 确保主控机器和远程执行机器之间的网络连接稳定
4. **资源**: 监控远程机器的磁盘空间，避免配置文件积累过多
5. **超时**: 不同任务类型有不同的超时时间，根据实际需要调整

## 故障排除

### 常见问题

1. **配置文件上传失败**
   - 检查SSH连接是否正常
   - 确认远程机器磁盘空间充足
   - 检查SCP命令的权限设置

2. **Docker容器启动失败**
   - 检查Docker镜像是否存在
   - 确认远程机器Docker服务运行正常
   - 检查挂载路径是否正确

3. **任务执行超时**
   - 检查任务配置是否合理
   - 增加超时时间设置
   - 查看容器日志排查具体问题
